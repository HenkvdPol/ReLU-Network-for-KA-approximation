# ReLU-Network-for-KA-approximation
given beta-holder continuous function f:[0,1]^d -> R, this deep ReLU network approximates f up to approximation rate of 2^(-beta) using 2^Kd parameters. Here, K is a set positive integer and d the dimension.
